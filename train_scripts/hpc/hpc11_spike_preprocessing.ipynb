{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "# using the code and from: https://github.com/zhd96/pi-vae/blob/main/examples/pi-vae_rat_data.ipynb\n",
    "# Zhou, D., Wei, X.\n",
    "# Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE.\n",
    "# NeurIPS 2020. https://arxiv.org/abs/2011.04798\n",
    "\n",
    "# you can download the preprocessed matfile from the pi-VAE authors:\n",
    "# https://drive.google.com/drive/folders/1lUVX1IvKZmw-uL2UWLxgx4NJ62YbCwMo?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(666)\n",
    "\n",
    "dataset_name = \"../../data_untracked/Achilles_data.mat\"\n",
    "\n",
    "rat_data = sio.loadmat(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load trial information\n",
    "idx_split = rat_data[\"trial\"][0]\n",
    "## load spike data\n",
    "spikes = rat_data[\"spikes\"]\n",
    "## load locations\n",
    "locs = rat_data[\"loc\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we didn't split the trials and train the model on this long trajectory\n",
    "# rather then presenting them one by one\n",
    "\n",
    "# but note that it is completely possible to also train the model using trials,\n",
    "# or also using the data where the all the recorded spikes were used during the maze epoch,\n",
    "# rather then sampling them only when the location data also exist, as is done here.\n",
    "# this effectively means having fs approximately 40Hz, as it's the sampling rate of the location,\n",
    "# as given in https://crcns.org/data-sets/hc/hc-11/about-hc-11\n",
    "\n",
    "# discard neurons that are silent\n",
    "spikes = spikes[:, np.sum(spikes, axis=0) > 230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(idx_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test, use the idx_split\n",
    "train_size = idx_split[int(idx_split.shape[0] * 0.71)]\n",
    "train_spikes = spikes[:train_size]\n",
    "test_spikes = spikes[train_size:]\n",
    "train_locs = locs[:train_size]\n",
    "test_locs = locs[train_size:]\n",
    "\n",
    "np.save(\"../../data_untracked/train_spikes_hpc11.npy\", train_spikes.T)\n",
    "np.save(\"../../data_untracked/test_spikes_hpc11.npy\", test_spikes.T)\n",
    "\n",
    "np.save(\"../../data_untracked/locs.npy\", locs)\n",
    "np.save(\"../../data_untracked/train_locs.npy\", train_locs)\n",
    "np.save(\"../../data_untracked/test_locs.npy\", test_locs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
