{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from neo.io.klustakwikio import KlustaKwikIO\n",
    "\n",
    "# download the data from the CRCNS website\n",
    "# https://crcns.org/data-sets/hc/hc-2/about-hc-2\n",
    "# Mizuseki K, Sirota A, Pastalkova E, BuzsÃ¡ki G., Neuron. 2009 Oct 29;64(2):267-80.\n",
    "# (http://www.ncbi.nlm.nih.gov/pubmed/19874793)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to hc2 data\n",
    "fs = 20_000\n",
    "datafile_dir = \"../../../Documents/crcns/hc2/ec013527/ec013527\"\n",
    "\n",
    "reader = KlustaKwikIO(dirname=str(datafile_dir), sampling_rate=fs)\n",
    "block = reader.read_block()\n",
    "\n",
    "# put all spike data into an array:\n",
    "spiketrains = block.segments[0].spiketrains\n",
    "n_units_pre = len(spiketrains)\n",
    "spikes = []\n",
    "for i in range(len(spiketrains)):\n",
    "    if (\n",
    "        block.segments[0].spiketrains[i].annotations[\"cluster\"] > 1\n",
    "    ):  # select only clustered units\n",
    "        spikes.append(np.array(spiketrains[i]))\n",
    "n_units = len(spikes)\n",
    "\n",
    "# plot all spikes\n",
    "cmap = mpl.colormaps[\"Pastel1\"]\n",
    "color = cmap(1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.eventplot(spikes, linewidths=0.5, colors=color)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Neuron\")\n",
    "# hide the right and top spines\n",
    "plt.gca().spines[\"right\"].set_visible(False)\n",
    "plt.gca().spines[\"top\"].set_visible(False)\n",
    "plt.gca().spines[\"left\"].set_visible(False)\n",
    "plt.gca().spines[\"bottom\"].set_visible(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in seconds. this is approximately 5 seconds longer than the actual recording,\n",
    "# so last bits are full of zeros which we'll cut later\n",
    "duration = 1065\n",
    "fs = 20000\n",
    "dt = 1 / fs\n",
    "\n",
    "t = np.arange(0, duration, dt)\n",
    "num_neurons = len(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert spike times into a binary matrix\n",
    "def spike_times_to_binary(spike_times, time_points):\n",
    "    num_neurons = len(spike_times)\n",
    "    num_time_points = len(time_points)\n",
    "    binary_matrix = np.zeros((num_neurons, num_time_points))\n",
    "\n",
    "    for i, times in enumerate(spike_times):\n",
    "        time_indices = np.searchsorted(time_points, times)\n",
    "        binary_matrix[i, time_indices] = 1\n",
    "\n",
    "    return binary_matrix\n",
    "\n",
    "\n",
    "binary_matrix = spike_times_to_binary(spikes, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting binary matrix to count matrix\n",
    "def bin_spike_data(binary_matrix, dt_original, dt_new):\n",
    "    # check if the new time resolution is a multiple of the original time resolution\n",
    "    if (dt_new / dt_original % 1) != 0:\n",
    "        raise ValueError(\n",
    "            \"New time resolution should be a multiple of the original time resolution.\"\n",
    "        )\n",
    "\n",
    "    # calculate the downsampling factor\n",
    "    factor = int(dt_new / dt_original)\n",
    "\n",
    "    # reshape the binary matrix to have a third dimension corresponding to the downsampling factor\n",
    "    reshaped_matrix = binary_matrix.reshape(binary_matrix.shape[0], -1, factor)\n",
    "\n",
    "    # sum along the third dimension to get the count matrix\n",
    "    count_matrix = np.sum(reshaped_matrix, axis=2)\n",
    "\n",
    "    return count_matrix\n",
    "\n",
    "\n",
    "count_matrix = bin_spike_data(binary_matrix, dt, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop neurons with too low spiking rate\n",
    "threshold = 0.1\n",
    "\n",
    "# take the sum of each row of count_matrix\n",
    "row_sum = np.sum(count_matrix, axis=1)\n",
    "thresholded = (row_sum / 1000) > threshold\n",
    "print(\n",
    "    \"dropping {:.2f}% of neurons\".format(\n",
    "        (1 - np.sum(thresholded) / len(thresholded)) * 100\n",
    "    )\n",
    ")\n",
    "\n",
    "# drop the rows that is false in thresholded in count_matrix\n",
    "count_matrix_filtered = count_matrix[thresholded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test set\n",
    "train_size = int(0.8 * count_matrix_filtered.shape[1])\n",
    "\n",
    "np.save(\"../../data_untracked/train_hpc2.npy\", count_matrix_filtered[:, :train_size])\n",
    "np.save(\"../../data_untracked/test_hpc2.npy\", count_matrix_filtered[:, train_size:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
