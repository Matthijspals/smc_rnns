{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import resample\n",
    "from scipy.signal import welch\n",
    "\n",
    "# download the data from: https://crcns.org/data-sets/hc/hc-11/about-hc-11\n",
    "# Grosmark, A.D., and Buzsáki, G. (2016). Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences. Science 351, 1440–1443.\n",
    "# Chen, Z., Grosmark, A.D., Penagos, H., and Wilson, M.A. (2016). Uncovering representations of sleep-associated hippocampal ensemble spike activity. Sci. Rep. 6, 32193.\n",
    "\n",
    "#for simplicity, we provided the Achilles_10252013 LFP data, that is sampled to fs = 100 Hz\n",
    "\n",
    "#LFP data, fs=100\n",
    "LFP_fs100 = np.load('../../data_untracked/Achilles_10252013_lfp_100Hz.npy') \n",
    "#zscore lfp\n",
    "LFP_fs100 = (LFP_fs100 - np.mean(LFP_fs100))/np.std(LFP_fs100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using the code from: https://github.com/zhd96/pi-vae/blob/main/examples/pi-vae_rat_data.ipynb\n",
    "## Zhou, D., Wei, X. Learning identifiable and interpretable latent models of high-dimensional neural activity using pi-VAE. NeurIPS 2020. https://arxiv.org/abs/2011.04798\n",
    "## we thank the authors for sharing their code publicly\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "with h5py.File('../../data_untracked/Achilles_10252013_sessInfo.mat', 'r') as f:\n",
    "    ## load spike info\n",
    "    spikes_times = np.array(f['sessInfo']['Spikes']['SpikeTimes'])[0];\n",
    "    \n",
    "    ## load location info ## all in maze\n",
    "    locations = np.array(f['sessInfo']['Position']['OneDLocation'])[0];\n",
    "    locations_times = np.array(f['sessInfo']['Position']['TimeStamps'])[:,0];\n",
    "    \n",
    "    ## load maze epoch range\n",
    "    maze_epoch = np.array(f['sessInfo']['Epochs']['MazeEpoch'])[:,0];\n",
    "\n",
    "# time in maze\n",
    "time_in_maze = ((spikes_times >= maze_epoch[0])*(spikes_times <= maze_epoch[1]));\n",
    "# spikes during maze epoch\n",
    "spikes_times = spikes_times[time_in_maze];\n",
    "\n",
    "# bin spikes and obtain number of time steps\n",
    "bin_size = 25; \n",
    "binned_spike_times = np.array(np.floor(spikes_times*1000/bin_size), dtype='int');\n",
    "n_times_steps = binned_spike_times.max() - binned_spike_times.min()+1\n",
    "\n",
    "# bin locations\n",
    "tph_binned_time = np.array(np.floor((np.arange(binned_spike_times.min(),binned_spike_times.max()+1)*bin_size/1000)*40), dtype='int');\n",
    "binned_locations_times = np.array(np.floor(locations_times*1000/bin_size), dtype='int');\n",
    "locations_vec = np.zeros(n_times_steps)+np.nan;\n",
    "\n",
    "for it in range(len(binned_locations_times)):\n",
    "    locations_vec[binned_locations_times[it] - binned_spike_times.min()] = locations[it];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs for below data was 100, here we downsample it to 40\n",
    "c, t, _ = LFP_fs100.shape\n",
    "ds = []\n",
    "for i in range(c):\n",
    "    lfp_temp = LFP_fs100[i,:]\n",
    "    resample_rate = 2.5\n",
    "    # resample\n",
    "    n_samples = int(len(lfp_temp)/resample_rate)\n",
    "    lfp_ds = resample(lfp_temp, n_samples)\n",
    "    ds.append(lfp_ds)\n",
    "\n",
    "LFP_fs40 = np.array(ds)\n",
    "LFP_fs40 = LFP_fs40[:,:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"resampled lfp shape timesteps \" + str(LFP_fs40.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mazeLFP = []  \n",
    "for i in range(LFP_fs40.shape[0]):\n",
    "    mazeLFP.append(LFP_fs40[i][np.unique(tph_binned_time)])\n",
    "mazeLFP = np.array(mazeLFP).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in run and no run\n",
    "norun_maze = mazeLFP[np.isnan(locations_vec)]\n",
    "run_maze = mazeLFP[~np.isnan(locations_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the 3 data sets\n",
    "np.save('../../data_untracked/norun_maze.npy', norun_maze)\n",
    "np.save('../../data_untracked/run_maze.npy', run_maze)\n",
    "np.save('../../data_untracked/full_maze.npy', mazeLFP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 40 # Hz\n",
    "nperseg = 1024\n",
    "#taking the mean along the channels is fine since they're highly correlated\n",
    "frequencies0, psd0 = welch(np.mean(run_maze, axis=1), fs=fs, nperseg=nperseg)  \n",
    "frequencies1, psd1 = welch(np.mean(norun_maze, axis=1), fs=fs, nperseg=nperseg)  \n",
    "frequencies2, psd2 = welch(np.mean(mazeLFP, axis=1), fs=fs, nperseg=nperseg) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq0 and freq1 subplots\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogy(frequencies0, psd0, alpha=0.8, zorder=0, label = 'run')\n",
    "plt.semilogy(frequencies1, psd1, alpha=0.8, zorder=0, label = 'rest')\n",
    "plt.semilogy(frequencies2, psd2, alpha=0.8, zorder=0, label = 'whole')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
