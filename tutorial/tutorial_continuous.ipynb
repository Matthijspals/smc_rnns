{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea98285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5bb93",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "We will use the `pytorch` `Dataset` class for handling the data\n",
    "\n",
    "Here we wil load some data of 20 artificial neurons that are noisy oscillators. This data is an array of dimensions `num_trials x num_units x sequence_length`, which we use to initialise a `Basic_dataset_with_trials`.\n",
    "\n",
    "If one has data without trial structure one can instead initialise the `Basic_dataset` class using an array of dimensions `num_units x sequence_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.datasets import Basic_dataset_with_trials\n",
    "\n",
    "# load data\n",
    "data_all = np.load(\"continuous_data.npy\")\n",
    "n_trials, dim_x, seq_len = data_all.shape\n",
    "\n",
    "# split into train and eval\n",
    "train_inds = np.full((n_trials,),False)\n",
    "train_inds[np.random.choice(np.arange(200),size=150,replace=False)]=True\n",
    "data_train = data_all[train_inds]\n",
    "data_eval = data_all[~train_inds]\n",
    "\n",
    "\n",
    "# initialise a dataset class\n",
    "task_params = {\"name\":\"tutorial_cont\"}\n",
    "dataset = Basic_dataset_with_trials(data=data_train,\n",
    "                                    data_eval = data_eval,\n",
    "                                    task_params=task_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some example data\n",
    "fig,ax = plt.subplots(1,2,figsize=(3,1))\n",
    "ax[0].plot(dataset.data[0].T);\n",
    "ax[1].plot(dataset.data[2].T);\n",
    "ax[0].set_xlim(0)\n",
    "ax[1].set_xlim(0)\n",
    "ax[0].set_xlabel(\"timesteps\")\n",
    "ax[1].set_xlabel(\"timesteps\")\n",
    "ax[0].set_title(\"activity in trial 0\")\n",
    "ax[1].set_title(\"activity in trial 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8b295",
   "metadata": {},
   "source": [
    "### Initialise the variational inference model\n",
    "\n",
    "for this we will instantiate the `VAE` class, which contains \n",
    "\n",
    "All the RNN parameters in:\n",
    "`vae.rnn`\n",
    "in particular the dynamics / transition model is in:\n",
    "`vae.rnn.transition`\n",
    "and the observation model is in:\n",
    "`vae.rnn.observation`\n",
    "\n",
    "If one trains an encoding network (not necessary for linear Gaussian observations), the encoder parameters are in `vae.encoder`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d465fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.vae import VAE\n",
    "\n",
    "\n",
    "\n",
    "enc_params = {} # we can leave this empty as we don't need to train an encoder for linear Gaussian observations\n",
    "\n",
    "rnn_params = {\n",
    "\n",
    "    # noise covariances settings\n",
    "    \"train_noise_x\": True, # whether or not to train the observation noise scale\n",
    "    \"train_noise_z\": True, # whether or not to train the transition noise scale\n",
    "    \"train_noise_z_t0\": True, # whether or not to train the initial state noise scale\n",
    "    \"init_noise_x\": .1, # initial scale of the observation noise\n",
    "    \"init_noise_z\": .1, # initial scale of the transition noise\n",
    "    \"init_noise_z_t0\": .1, # initial scale of the initial state noise\n",
    "     \"noise_x\": \"diag\", # observation covariance type (\"diag\" or \"scalar\"), can generally be left as diagional\n",
    "    \"noise_z\": \"full\", # transition noise covariance type (\"full\", \"diag\" or \"scalar\"), set to \"full\" when using the optimal proposal\n",
    "    \"noise_z_t0\": \"full\", # initial state noise covariance type (\"full\", \"diag\" or \"scalar\"), set to \"full\" when using the optimal proposal\n",
    "\n",
    "    # readout settings\n",
    "    \"identity_readout\": True, # if True enforces a one to one mapping between RNN units and recorded units\n",
    "    \"readout_from\": \"currents\", # set to \"currents\", \"rates\", \"z\" or \"z_and_v\". We can readout from the RNN activity \n",
    "                                # before / after applying the non-linearty by setting this to \"currents\" / \"rates\" respectively.\n",
    "                                # Alternatively we can directly readout from the latent dynamics z of the RNN by \n",
    "                                # setting this to \"z\", or from latents z and input v, by setting this to \"z_and_v\"\n",
    "    \"train_obs_bias\": False, # whether or not to train a bias term in the observation model\n",
    "    \"train_obs_weights\": False, # whether or not train the weights of the observation model \n",
    "    \"out_nonlinearity\":\"identity\", # can be used to rectify the output when using Poisson observations\n",
    "\n",
    "    # other \n",
    "    \"activation\": \"relu\", # set the nonlinearity to \"clipped_relu, \"relu\", \"tanh\" or \"identity\"\n",
    "    \"decay\":.9, # initial decay constant, scalar between 0 and 1\n",
    "    \"train_neuron_bias\": True, # train a bias term for every neuron\n",
    "    \"weight_dist\": \"uniform\", # weight distribution (\"uniform\" or \"gauss\")\n",
    "    \"initial_state\": \"trainable\", # initial state (\"trainable\", \"zero\", or \"bias\")\n",
    "}\n",
    "\n",
    "\n",
    "VAE_params = {\n",
    "    \"dim_x\": 20, # observation dimension (number of units in the data)\n",
    "    \"dim_z\": 2, # latent dimension / rank of the RNN\n",
    "    \"dim_N\": 20, # amount of units in the RNN (can generally be different then the observation dim)\n",
    "    \"enc_architecture\": \"Inv_Obs\", # encoder architecture (not trained when using linear Gauss observations)\n",
    "    \"enc_params\": enc_params, # encoder params\n",
    "    \"rnn_architecture\": \"LRRNN\", # use a low-rank RNN architecture\n",
    "    \"rnn_params\": rnn_params, # parameters of the RNN\n",
    "}\n",
    "\n",
    "# initialise the VAE\n",
    "vae = VAE(VAE_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735937",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "vae.forward_optimal_proposal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.saving import save_model\n",
    "from vi_rnn.train import train_VAE\n",
    "\n",
    "training_params = {\n",
    "    \"lr\": 1e-3, # learning rate start\n",
    "    \"lr_end\": 1e-5, # learning rate end (with exponential decay)\n",
    "    \"n_epochs\": 1000, # number of epochs to train\n",
    "    \"grad_norm\": 0, # gradient clipping above certain norm (if this is set to >0)\n",
    "    \"batch_size\": 16, # batch size\n",
    "    \"cuda\": False, # train on GPU\n",
    "    \"k\": 64, # number of particles to use\n",
    "    \"loss_f\": \"opt_smc\", # use regular variational SMC (\"smc\"), or use the optimal (\"opt_smc\") or bootstrap (\"bs_smc\") proposal\n",
    "    \"resample\": \"systematic\",  # , multinomial or none\"\n",
    "    \"run_eval\": False, # run an evaluation setup during training\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "#wandb=True\n",
    "train_VAE(vae, training_params, dataset, sync_wandb=False, out_dir=\"\", fname=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8385da",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(vae, training_params, task_params, name=\"tutorial_cont\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37bec1c",
   "metadata": {},
   "source": [
    "### Plot the trained model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.evaluation import predict\n",
    "Z, data_gen, rates = predict(vae,u=None,x=dataset.data_eval,initial_state=\"posterior_mean\",optimal_proposal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d89ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vi_rnn.utils import get_orth_proj_latents\n",
    "projection_matrix = get_orth_proj_latents(vae)\n",
    "Z_orth = np.einsum(\"BZT,OZ->BOT\",Z,projection_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,3)\n",
    "ax[0,0].plot(dataset.data_eval[0].T);\n",
    "ax[0,1].plot(dataset.data_eval[1].T);\n",
    "ax[0,2].plot(dataset.data_eval[2].T);\n",
    "\n",
    "ax[1,0].plot(data_gen[0].T);\n",
    "ax[1,1].plot(data_gen[1].T);\n",
    "ax[1,2].plot(data_gen[2].T);\n",
    "\n",
    "\n",
    "ax[2,0].plot(Z_orth[0].T);\n",
    "ax[2,1].plot(Z_orth[1].T);\n",
    "ax[2,2].plot(Z_orth[2].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3093aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smc_rnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
