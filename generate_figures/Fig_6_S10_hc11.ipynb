{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "file_dir = os.getcwd()\n",
    "sys.path.append(file_dir + \"/../\")\n",
    "import torch\n",
    "import numpy as np\n",
    "from vi_rnn.saving import load_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from evaluation.calc_stats import calc_isi_stats, calculate_correlation\n",
    "from vi_rnn.saving import load_model\n",
    "from vi_rnn.utils import get_orth_proj_latents\n",
    "from scipy.stats import zscore\n",
    "from scipy.signal import hann, welch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# we are using data from: https://crcns.org/data-sets/hc/hc-11/about-hc-11\n",
    "# Grosmark, A.D., and Buzsáki, G. (2016). Diversity in neural firing dynamics supports both rigid and learned hippocampal sequences. Science 351, 1440–1443.\n",
    "# Chen, Z., Grosmark, A.D., Penagos, H., and Wilson, M.A. (2016). Uncovering representations of sleep-associated hippocampal ensemble spike activity. Sci. Rep. 6, 32193."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "filename = \"../models/hpc11/hc11rank4e2\"\n",
    "filename = \"../models/hpc11/_CNN_causal_PLRNN_Z_Date_122024_06_24_T_17_54_22\"\n",
    "vae, params, task_params, training_params = load_model(str(filename))\n",
    "rank = vae.dim_z\n",
    "vae = vae.eval()\n",
    "\n",
    "\n",
    "# load spiking data\n",
    "train_data = np.load(\"../data_untracked/train_spikes_hpc11.npy\")\n",
    "test_data = np.load(\"../data_untracked/test_spikes_hpc11.npy\")\n",
    "dim_x, T = test_data.shape\n",
    "_, T_train = train_data.shape\n",
    "print(\"Spiking data shape: \", test_data.shape)\n",
    "\n",
    "# load lfp\n",
    "lfp = np.load(\"../data_untracked/mazeLFP.npy\").T\n",
    "\n",
    "# load locations\n",
    "test_locs = np.load(\"../data_untracked/test_locs.npy\")\n",
    "train_locs = np.load(\"../data_untracked/train_locs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained network\n",
    "\n",
    "# get data inferred initial state\n",
    "z_hat, _, _, _ = vae.encoder(torch.from_numpy(test_data)[:, :1000].float().unsqueeze(0))\n",
    "z0 = z_hat[:1, :, :1]\n",
    "\n",
    "# get latent trajectory (cut first 1000 time steps)\n",
    "Z = vae.rnn.get_latent_time_series(time_steps=T, cut_off=1000, z0=z0, noise_scale=1)\n",
    "\n",
    "# get spikes\n",
    "lam = vae.rnn.get_observation(Z, noise_scale=0)[0, :, :, 0]\n",
    "spikes_pred = torch.poisson(lam).T.detach().numpy()\n",
    "\n",
    "# project latents on orthogonalised connnectivity and normalise\n",
    "projection_matrix = get_orth_proj_latents(vae)\n",
    "Z = projection_matrix @ Z[0, :, :, 0]\n",
    "prior_Z = zscore(Z.detach().numpy(), axis=1)\n",
    "\n",
    "# get posterior latents given test\n",
    "k = 128  # number of particles\n",
    "with torch.no_grad():\n",
    "    Qzs_filt_avg, Qzs_sm_avg, Xs_filt_avg, Xs_sm_avg = vae.predict_NLB(\n",
    "        torch.from_numpy(test_data).float().unsqueeze(0),\n",
    "        u=None,\n",
    "        k=k,\n",
    "        t_held_in=T,\n",
    "        t_forward=0,\n",
    "        marginal_smoothing=False,\n",
    "    )\n",
    "Qzs_filt_avg = Qzs_filt_avg[0].mean(axis=-1)  # average over particles\n",
    "Qzs_filt_avg = (\n",
    "    projection_matrix @ Qzs_filt_avg\n",
    ")  # project on orthogonalised connectivity\n",
    "post_Z = zscore(Qzs_filt_avg.detach().numpy(), axis=1)  # normalise\n",
    "\n",
    "# get posterior latents given train\n",
    "k = 128  # number of particles\n",
    "with torch.no_grad():\n",
    "    Qzs_filt_avg, Qzs_sm_avg, Xs_filt_avg, Xs_sm_avg = vae.predict_NLB(\n",
    "        torch.from_numpy(train_data).float().unsqueeze(0),\n",
    "        u=None,\n",
    "        k=k,\n",
    "        t_held_in=T_train,\n",
    "        t_forward=0,\n",
    "        marginal_smoothing=False,\n",
    "    )\n",
    "Qzs_filt_avg = Qzs_filt_avg[0].mean(axis=-1)  # average over particles\n",
    "Qzs_filt_avg = (\n",
    "    projection_matrix @ Qzs_filt_avg\n",
    ")  # project on orthogonalised connectivity\n",
    "post_Z_train = zscore(Qzs_filt_avg.detach().numpy(), axis=1)  # normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zcore lfp\n",
    "lfp = zscore(lfp, axis=1)\n",
    "\n",
    "# taking the mean along the channels, since channels are highly correlated\n",
    "lfp = np.mean(lfp, axis=0)\n",
    "\n",
    "# split the LFP into train and test the same as we did for spikes\n",
    "train_lfp = lfp[:T_train]\n",
    "test_lfp = lfp[T_train:]\n",
    "\n",
    "fs = 39  # Hz\n",
    "nperseg = 1024\n",
    "f_test_lfp, psd_test_lfp = welch(\n",
    "    test_lfp.reshape(-1), fs=fs, nperseg=nperseg\n",
    ")  # Adjust nperseg as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain power spectral density of the prior latents\n",
    "\n",
    "fs = 39  # Hz\n",
    "nperseg = 400\n",
    "\n",
    "f_pZ1, psd_pZ1 = welch(prior_Z[0], fs=fs, nperseg=nperseg)\n",
    "f_pZ2, psd_pZ2 = welch(prior_Z[1], fs=fs, nperseg=nperseg)\n",
    "f_pZ3, psd_pZ3 = welch(prior_Z[2], fs=fs, nperseg=nperseg)\n",
    "f_pZ4, psd_pZ4 = welch(prior_Z[3], fs=fs, nperseg=nperseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression from latents to LFP\n",
    "\n",
    "\n",
    "# Define the model and fit it\n",
    "model = LinearRegression()\n",
    "\n",
    "X = np.vstack((post_Z_train[0], post_Z_train[1], post_Z_train[2], post_Z_train[3])).T\n",
    "X_test = np.vstack((post_Z[0], post_Z[1], post_Z[2], post_Z[3])).T\n",
    "y = train_locs\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = model.score(X_test, test_locs)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"Corr. coef:\", np.corrcoef(test_locs, y_pred)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression from latents to LFP\n",
    "\n",
    "# Define the model and fit it\n",
    "model = LinearRegression()\n",
    "\n",
    "kw = 101\n",
    "\n",
    "# kernel = np.ones(kw) / kw\n",
    "kernel = hann(kw)\n",
    "post_Z_trainks0 = np.convolve(post_Z_train[0], kernel, mode=\"same\")\n",
    "post_Z_trainks1 = np.convolve(post_Z_train[1], kernel, mode=\"same\")\n",
    "post_Z_trainks2 = np.convolve(post_Z_train[2], kernel, mode=\"same\")\n",
    "post_Z_trainks3 = np.convolve(post_Z_train[3], kernel, mode=\"same\")\n",
    "\n",
    "post_Zks0 = np.convolve(post_Z[0], kernel, mode=\"same\")\n",
    "post_Zks1 = np.convolve(post_Z[1], kernel, mode=\"same\")\n",
    "post_Zks2 = np.convolve(post_Z[2], kernel, mode=\"same\")\n",
    "post_Zks3 = np.convolve(post_Z[3], kernel, mode=\"same\")\n",
    "\n",
    "X = np.vstack((post_Z_trainks0, post_Z_trainks1, post_Z_trainks2, post_Z_trainks3)).T\n",
    "X_test = np.vstack((post_Zks0, post_Zks1, post_Zks2, post_Zks3)).T\n",
    "y = train_locs\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = model.score(X_test, test_locs)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"Corr. coef:\", np.corrcoef(test_locs, y_pred)[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get firing rates\n",
    "fs = 39\n",
    "fr_test = np.mean(test_data, axis=1) * fs\n",
    "fr_train = np.mean(train_data, axis=1) * fs\n",
    "fr_gen = np.mean(spikes_pred, axis=0) * fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrices\n",
    "test_correlation = calculate_correlation(test_data.T)\n",
    "gen_correlation = calculate_correlation(spikes_pred)\n",
    "train_correlation = calculate_correlation(train_data.T)\n",
    "\n",
    "# Extracting upper triangle values without the diagonal\n",
    "i_upper = np.triu_indices(dim_x, k=1)\n",
    "test_corr_values = test_correlation[i_upper]\n",
    "gen_corr_values = gen_correlation[i_upper]\n",
    "train_corr_values = train_correlation[i_upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ISI stats\n",
    "\n",
    "CVs_isi_test, Means_isi_test, Std_isi_test = calc_isi_stats(test_data.T, dt=1 / fs)\n",
    "CVs_isi_gen, Means_isi_gen, Std_isi_gen = calc_isi_stats(spikes_pred, dt=1 / fs)\n",
    "CVs_isi_train, Means_isi_train, Std_isi_train = calc_isi_stats(train_data.T, dt=1 / fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = \"#7B46C1\"\n",
    "color2 = \"#A860AF\"\n",
    "color3 = \"#7C277D\"\n",
    "color4 = \"#8A44A4\"\n",
    "tg = \"teal\"\n",
    "tr = \"firebrick\"\n",
    "cmap = plt.get_cmap(\"tab20b\")\n",
    "cmap2 = plt.get_cmap(\"Dark2\")\n",
    "\n",
    "with mpl.rc_context(fname=\"matplotlibrc\"):\n",
    "\n",
    "    # Create a figure with specified size\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(6, 3))\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.6)\n",
    "\n",
    "    ax1 = axes[0, 0]\n",
    "    ax2 = axes[0, 2]\n",
    "    ax3 = axes[0, 1]\n",
    "    ax4 = axes[1, 0]\n",
    "    ax5 = axes[1, 1]\n",
    "    ax6 = axes[1, 2]\n",
    "    ax7 = axes[1, 3]\n",
    "    ax8 = axes[0, 3]\n",
    "\n",
    "    # extract the width gap\n",
    "    gap = ax5.get_position().x0 - ax4.get_position().x1\n",
    "\n",
    "    # manually set the position for ax8\n",
    "    pos = axes[1, 3].get_position()  # Get position of the third plot\n",
    "    ax8.set_position([pos.x0 + pos.width + gap, pos.y0, pos.width, pos.height])\n",
    "\n",
    "    # manually adjust the locations of wider plots\n",
    "    width_scaling_factor = 1.6\n",
    "    new_positions = []\n",
    "\n",
    "    for i, ax in enumerate(axes[0, :3]):\n",
    "        pos = ax.get_position()\n",
    "        if i == 0:\n",
    "            new_positions.append(\n",
    "                [pos.x0, pos.y0, pos.width * width_scaling_factor, pos.height]\n",
    "            )\n",
    "        else:\n",
    "            new_positions.append(\n",
    "                [\n",
    "                    new_positions[i - 1][0] + new_positions[i - 1][2] + gap * 4 / 2.1,\n",
    "                    pos.y0,\n",
    "                    pos.width * width_scaling_factor,\n",
    "                    pos.height,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    for i, ax in enumerate(axes[0, :3]):\n",
    "        ax.set_position(new_positions[i])\n",
    "\n",
    "    # data spikes\n",
    "    sec = 20\n",
    "    init = 750\n",
    "    duration = sec * 40\n",
    "    ax1.imshow(\n",
    "        test_data[:, init : init + duration],\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"Greys\",\n",
    "        interpolation=\"none\",\n",
    "        vmax=1,\n",
    "    )\n",
    "    ax1.set_xticks([0, 10 * 40, 20 * 40])\n",
    "    ax1.set_xticklabels([0, 10, 20])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_title(\"data\")\n",
    "    ax1.set_ylabel(\"neuron\")\n",
    "    ax1.set_xlabel(\"time (s)\")\n",
    "\n",
    "    # generated spikes\n",
    "    ax3.imshow(\n",
    "        spikes_pred[init : init + duration, :].T,\n",
    "        aspect=\"auto\",\n",
    "        cmap=\"Greys\",\n",
    "        interpolation=\"none\",\n",
    "        vmax=1,\n",
    "    )\n",
    "    ax3.set_xticks([0, 10 * 40, 20 * 40])\n",
    "    ax3.set_xticklabels([0, 10, 20])\n",
    "    ax3.set_title(\"generated spikes\")\n",
    "    ax3.set_xlabel(\"time (s)\")\n",
    "    ax3.set_yticks([])\n",
    "\n",
    "    # latents\n",
    "    t = np.linspace(0, sec, duration)\n",
    "    ax2.plot(\n",
    "        t, prior_Z[0][init : init + duration] + 5, alpha=0.9, label=\"Z1\", color=color1\n",
    "    )\n",
    "    ax2.plot(t, prior_Z[1][init : init + duration], alpha=0.9, label=\"Z2\", color=color2)\n",
    "    ax2.plot(\n",
    "        t, prior_Z[2][init : init + duration] - 5, alpha=0.9, label=\"Z3\", color=color3\n",
    "    )\n",
    "    ax2.plot(\n",
    "        t, prior_Z[3][init : init + duration] - 10, alpha=0.9, label=\"Z4\", color=color4\n",
    "    )\n",
    "    ax2.set_xlim(0, sec)\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xticks([0, 10, 20])\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlabel(\"time (s)\")\n",
    "    ax2.set_title(\"latents\")\n",
    "\n",
    "    # coefficient of variation\n",
    "    n_dots = len(CVs_isi_test)\n",
    "    zorders = np.arange(n_dots * 2)\n",
    "    np.random.shuffle(zorders)\n",
    "    for i in range(n_dots):\n",
    "        ax5.scatter(\n",
    "            CVs_isi_test[i],\n",
    "            CVs_isi_gen[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tg,\n",
    "            zorder=zorders[i],\n",
    "        )\n",
    "        ax5.scatter(\n",
    "            CVs_isi_test[i],\n",
    "            CVs_isi_train[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tr,\n",
    "            label=\"train\",\n",
    "            zorder=zorders[i + n_dots],\n",
    "        )\n",
    "\n",
    "    ax5.plot([0, 4], [0, 4], color=\"gray\", linestyle=\"--\", zorder=0)\n",
    "    ax5.set_title(\"cv ISIs\")\n",
    "    ax5.set_xticks([0, 4])\n",
    "    ax5.set_yticks([0, 4])\n",
    "    ax5.set_xlabel(\"test\")\n",
    "    ax5.set_xlim([0, 4])\n",
    "    ax5.set_ylim([0, 4])\n",
    "\n",
    "    # mean rates\n",
    "    ax4.plot(\n",
    "        np.linspace(0, 10, 20),\n",
    "        np.linspace(0, 10, 20),\n",
    "        color=\"gray\",\n",
    "        linestyle=\"--\",\n",
    "        zorder=0,\n",
    "    )\n",
    "    n_dots = len(fr_test)\n",
    "    zorders = np.arange(n_dots * 2)\n",
    "    np.random.shuffle(zorders)\n",
    "    for i in range(n_dots):\n",
    "        ax4.scatter(fr_test[i], fr_gen[i], s=10, alpha=0.7, color=tg, zorder=zorders[i])\n",
    "        ax4.scatter(\n",
    "            fr_test[i],\n",
    "            fr_train[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tr,\n",
    "            zorder=zorders[i + n_dots],\n",
    "        )\n",
    "\n",
    "    ax4.set_title(\"mean rates (hz)\")\n",
    "    ax4.set_xticks([1, 10])\n",
    "    ax4.set_yticks([1, 10])\n",
    "    ax4.set_xlabel(\"test\")\n",
    "    ax4.set_ylabel(\"gen / train\")\n",
    "\n",
    "    # custom legend labels and colors\n",
    "    legend_labels = [\"test/gen\", \"test/train\"]\n",
    "    legend_colors = [tg, tr]\n",
    "\n",
    "    # add custom legend\n",
    "    legend_elements = [\n",
    "        plt.Line2D([0], [0], color=color, lw=0, label=label)\n",
    "        for color, label in zip(legend_colors, legend_labels)\n",
    "    ]\n",
    "    legend = ax4.legend(\n",
    "        handles=legend_elements,\n",
    "        handletextpad=0,\n",
    "        handlelength=0,\n",
    "        fancybox=True,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.16, 0.45),\n",
    "        fontsize=6,\n",
    "    )\n",
    "\n",
    "    for text, color in zip(legend.get_texts(), legend_colors):\n",
    "        text.set_color(color)\n",
    "\n",
    "    # pairwise correlation\n",
    "    ax6.plot([-0.1, 0.2], [-0.1, 0.2], color=\"gray\", linestyle=\"--\", zorder=0)\n",
    "    dots = len(test_corr_values)\n",
    "    zorders = np.arange(n_dots * 2)\n",
    "    np.random.shuffle(zorders)\n",
    "    for i in range(n_dots):\n",
    "        ax6.scatter(\n",
    "            test_corr_values[i],\n",
    "            gen_corr_values[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tg,\n",
    "            zorder=zorders[i],\n",
    "        )\n",
    "        ax6.scatter(\n",
    "            test_corr_values[i],\n",
    "            train_corr_values[i],\n",
    "            s=10,\n",
    "            alpha=0.7,\n",
    "            color=tr,\n",
    "            label=\"train\",\n",
    "            zorder=zorders[i + n_dots],\n",
    "        )\n",
    "\n",
    "    ax6.tick_params(axis=\"x\", which=\"both\", width=1)\n",
    "    ax6.tick_params(axis=\"y\", which=\"both\", width=1)\n",
    "    ax6.set_title(\"pairwise corr.\")\n",
    "    ax6.set_xlabel(\"test\")\n",
    "    ax6.set_yticks([-0.1, 0.2])\n",
    "    ax6.set_yticklabels([\"-0.1\", \"0.2\"])\n",
    "    ax6.set_xticks([-0.1, 0.2])\n",
    "    ax6.set_xticklabels([\"-0.1\", \"0.2\"])\n",
    "    ax6.set_xlim([-0.1, 0.2])\n",
    "    ax6.set_ylim([-0.1, 0.2])\n",
    "    # psd\n",
    "    (line1,) = ax8.semilogy(\n",
    "        f_pZ1, psd_pZ1, color=color1, alpha=0.9, zorder=0, label=\"z 2\"\n",
    "    )\n",
    "    (line2,) = ax8.semilogy(\n",
    "        f_pZ2, psd_pZ2, color=color2, alpha=0.9, zorder=0, label=\"z 3\"\n",
    "    )\n",
    "    (line3,) = ax8.semilogy(\n",
    "        f_pZ3, psd_pZ3, color=color3, alpha=0.9, zorder=0, label=\"z 1\"\n",
    "    )\n",
    "    (line4,) = ax8.semilogy(\n",
    "        f_pZ4, psd_pZ4, color=color4, alpha=0.9, zorder=0, label=\"z 1\"\n",
    "    )\n",
    "    (line5,) = ax8.semilogy(\n",
    "        f_test_lfp, psd_test_lfp, color=\"black\", alpha=0.6, zorder=0, label=\"LFP\"\n",
    "    )\n",
    "    ax8.set_xlim([0, 20])\n",
    "    ax8.set_ylim([10**-4, 1])\n",
    "    ax8.set_title(\"psd\")\n",
    "    ax8.set_xlabel(\"frequency (hz)\")\n",
    "    ax8.tick_params(axis=\"y\", which=\"both\", width=1)\n",
    "\n",
    "    # custom legend handles. note: legends were manually adjusted using illustrator afterwards to include the LFP signal\n",
    "    legend_labels = [\"$z_1$\", \"$z_2$\", \"$z_3$\", \"$z_4$\"]\n",
    "    legend_colors = [color1, color2, color3, color4]\n",
    "\n",
    "    legend = ax8.legend(\n",
    "        legend_labels,\n",
    "        handletextpad=0,\n",
    "        handlelength=0,\n",
    "        fancybox=True,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.2, 2.95),\n",
    "    )\n",
    "    for text, color in zip(legend.get_texts(), legend_colors):\n",
    "        text.set_color(color)\n",
    "\n",
    "    ax8.set_yticks([0.001, 0.1])\n",
    "    ax8.set_yticklabels([\"0.001\", \"0.1\"])\n",
    "    ax8.set_xticks([0.2, 10, 20])\n",
    "\n",
    "    # LFP and zoomed latents\n",
    "    init = int(18.3 * 40) + 1160\n",
    "    duration = 1 * 40\n",
    "    t = np.linspace(0, 1, duration)\n",
    "\n",
    "    # note: we shifted the signals for better visualization\n",
    "    ax7.plot(\n",
    "        t, prior_Z[0][init : init + duration] + 5, alpha=0.9, label=\"Z1\", color=color1\n",
    "    )\n",
    "    ax7.plot(t, prior_Z[1][init : init + duration], alpha=0.9, label=\"Z4\", color=color2)\n",
    "    ax7.plot(\n",
    "        t, prior_Z[2][init : init + duration] - 5, alpha=0.9, label=\"Z3\", color=color3\n",
    "    )\n",
    "    ax7.plot(\n",
    "        t, prior_Z[3][init : init + duration] - 10, alpha=0.9, label=\"Z2\", color=color4\n",
    "    )\n",
    "\n",
    "    cc = test_lfp[init : init + duration] + 12\n",
    "    ax7.plot(t, cc, alpha=0.7, label=\"LFP\", color=\"black\")\n",
    "    ax7.set_xlim([0, 1])\n",
    "    ax7.set_xticks([0, 1])\n",
    "    ax7.set_yticks([])\n",
    "    ax7.set_xlabel(\"time (s)\")\n",
    "    ax7.set_title(\"latents and LFP\")\n",
    "\n",
    "    plt.gcf().set_size_inches(5.2, 3)\n",
    "\n",
    "    ax1.set_box_aspect(0.625)\n",
    "    ax2.set_box_aspect(0.625)\n",
    "    ax3.set_box_aspect(0.625)\n",
    "    ax7.set_box_aspect(1)\n",
    "    ax4.set_box_aspect(1)\n",
    "    ax5.set_box_aspect(1)\n",
    "    ax6.set_box_aspect(1)\n",
    "    ax8.set_box_aspect(1)\n",
    "\n",
    "    plt.savefig(\"../figures/hpc11_main.png\", dpi=300)\n",
    "    plt.savefig(\"../figures/hpc11_maincorfon.pdf\", dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mpl.rc_context(fname=\"matplotlibrc\"):\n",
    "\n",
    "    pr = \"#9BB5DE\"\n",
    "    rat = \"#2B3073\"\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    plt.plot(y_pred, color=pr, alpha=0.7, label=\"predicted\", linewidth=1)\n",
    "    plt.plot(test_locs, alpha=0.7, color=rat, label=\"rat\", linewidth=1.5)\n",
    "    plt.legend()\n",
    "\n",
    "    # divide x axis by fs to convert to seconds\n",
    "    # but note that we cropped the signal and only show\n",
    "    # the first 30 seconds in the main figure to make the plot more readable\n",
    "    plt.xticks([0, 2000, 4000], [0, round(2000 / fs, 2), round(4000 / fs, 2)])\n",
    "    legend_labels = [\"predicted\", \"rat\"]\n",
    "    legend_colors = [pr, rat]\n",
    "\n",
    "    legend = plt.legend(\n",
    "        legend_labels,\n",
    "        handletextpad=0,\n",
    "        handlelength=0,\n",
    "        fancybox=True,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(1.12, 0.6),\n",
    "    )\n",
    "    for text, color in zip(legend.get_texts(), legend_colors):\n",
    "        text.set_color(color)\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    plt.yticks([])\n",
    "    plt.title(\"location\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
